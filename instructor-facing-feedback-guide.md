# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Providing Project Feedback
> _Every student should have a chance to understand how they're doing and to get valuable feedback on the work they've done from trusted mentors in the classroom._

Specific, timely feedback is critical to student learning. Our goal is to provide meaningful suggestions and guidance to all of our students. While there will undoubtedly be nuances in individual student portfolio evaluation, use these guidelines to ensure that your students get the personalized feedback they deserve.

Our evaluation approach pairs a numeric "grade" (useful for tracking student performance over the course) with instructor-provided qualitative feedback (useful for coaching and improving student performance).

Below, we'll walk you through:

1. [What to Grade](#what)
2. [Why we Grade](#why)
3. [How to Grade](#how)
4. [Unit vs Capstone Projects](#types)
5. [How to Deliver/Discuss Grades](#feedback)
6. [Example Feedback](#example)

---

<a id='what'></a>
## I. What to Grade
In DSI, students are required to complete **all 5 deliverables** from their Capstone Project, **all four of our Unit Projects**,  well as **80% of any additional assignments**. 

### Mandated Course Completion Requirements
- [ ] Capstone Deliverables 1-5
- [ ] Unit Projects 1-4
- [ ] 80% of all assigned work

In practice, this 80% requirements means attendance and participation in all daily activities, completion of labs and classwork, and submission of other outcomes-related homework or group assignments. Data has shown that students who complete these assignments perform more favorably in interviews and are generally more prepared for outcomes support, so we strongly recommend that you enforce completion of day to day course activities.

### Optional Course Requirements 
- [ ] Group Projects (i.e. Kaggle) and Weekly Assignments
- [ ] Blog and Portfolio Development
- [ ] Labs and Homework


Daily assignments outside of the core required capstone and unit project deliverables do not require specific feedback from instructors. Personalized feedback should be reserved for student projects. Set this expectation early and consistently.

---

<a id='why'></a>
## II. Why We Grade

Below are a few high level principles and best practices for providing feedback on student projects at GA:

### Guiding Principles for Project Feedback

- Grading provides structured feedback to students
- Grading defines clear targets for student performance
- Grading verifies continued progress and improvement by a student throughout the course

### Best Practices for Project Feedback 

- Review project requirments and rubrics with students early on, so that they know how they will be assessed.
- Focus your project feedback on **required** project components
- Work with your local team to provide timely, targeted feedback for **every** project

---

<a id='how'></a>
## III. How to Grade

Next, we'll walk you through the specific steps necessary to grade a student project.

#### How to Grade Projects

1. Make a copy of the project requirements.
2. Use our rubric to assign a point value for all required items.
3. Provide at least one comment for each requirements. 

> We recommend following a "glow/grow" template, with one item of praise and one suggestion for improvement.


### GA Rubric
Here at GA, we use a simple 3 point scale. Using the guideline below, assess how well students performed on all required sections on a scale of 0-2, and share those scores in your feedback:

Score | Expectations
:--- | :---
**0** | _Incomplete._
**1** | _Does not meet expectations._
**2** | _Meets expectations, good job!_


> We used to add an additional integer for "exceeding expectations" but discontinued this - in practice, it set inconsistent standards for students and instructors, and did not necessarily apply to all GA project requirements.

---

<a id='types'></a>
## IV. Unit vs Capstone Projects

Next we'll walk you through some differences in grading unit projects vs capstone projects.

### Grading Unit Projects

In DSI, unit project questions are assigned a difficulty level, denoted by colored badges: **Required**, **Bonus**, and **Challenge**. Students are told to complete all of the **Required** sections, which they can expect feedback on. 

> Bonus and Challenge sections are optional; therefore, students should not expect feedback on those sections. These are intended primarily for differentiation and enrichment, to provide stretch goals for students to push themselves.

In preparing qualitative feedback for students, consider how well students performed in each of these required questions. Your feedback here should be *diagnostic* and *constructive*. In other words, review responses for specific gaps in performance and offer concrete suggestions for improvement.

Additionally, each unit project's description includes a **"Requirements" rubric**, which lists the competencies students are expected to demonstrate in their work. Based on your diagnostic review of their submission, use this rubric to assign a point value for each item.

#### EXAMPLE

For example, the Unit Project 1 might ask students to demonstrate:

  - Command of basic Python data structures
  - Command of basic Python syntax and control log
  - Comfort with calculating basic descriptive statistics

Using our scale of 0-2, you would input scores for each line, resulting in an overall total for that student's project.

Score  | Expectations
--- | ---
**0** | _Incomplete._
**1** | _Does not meet expectations._
**2** | _Meets expectations, good job!_

This becomes:

  - Command of basic Python data structures  - **SCORE + COMMENT**
  - Command of basic Python syntax and control log  - **SCORE + COMMENT**
  - Comfort with calculating basic descriptive statistics - **SCORE + COMMENT**

**TOTAL SCORE + OVERALL COMMENTS**

---

### Capstone Project Grading

Capstone projects do not use the same tiered challenge structure as the unit projects. Instead, capstones simply define a core set of requirements that should inform your evaluation of the student's work. 

As before, you are only responsible for scoring and providing feedback on any "Required" sections. Assign a relative score to the numbered portions, and then fill in any qualitative feedback on the student's work.

#### EXAMPLE

For example, in Capstone Part 1, the "Required" portion asks students to:

1. Prepare a slide deck and host a 3-5 minute lightning talk on **at least two** potential topics for your DSI capstone project. For each topic, define all required areas:

2. Topic 1 (etc):
   - Problem Statement
   - Potential Audience 
   - Goals
   - Success Metrics
   - Data Source(s)

Instructors should use their best judgement to **score** each of these *numbered requirements* using the GA rubric:

Score | Expectations
:--- | :---
**0** | _Incomplete._
**1** | _Does not meet expectations._
**2** | _Meets expectations, good job!_

Which Becomes:

1. Prepare a slide deck and host a 3-5 minute lightning talk on **at least two** potential topics for your DSI capstone project. 
**SCORE** (+ **COMMENT** as needed)

2. Topic 1: **SCORE**
   - Problem Statement: **COMMENT**
   - Potential Audience: **COMMENT**
   - Goals: **COMMENT**
   - Success Metrics: **COMMENT**
   - Data Source(s): **COMMENT**
   
**TOTAL SCORE** + **OVERALL COMMENTS**

---

### Capstone Project Standards
For capstone deliverables, instructors may also find it helpful to structure their evaluation by reviewing the student's performance against the suggested standards included from our DSI data science workflow:

- [ ] Identify Problem
- [ ] Acquire Data
- [ ] Parse Data
- [ ] Mine Data
- [ ] Refine Data       
- [ ] Model Data
- [ ] Present Results
- [ ] Deploy Data

#### EXAMPLE

For example, in Capstone, Part 1, the DSI standards listed on the rubric are:
- [ ] Identify Problem 
- [ ] Acquire Data 
- [ ] Present Data 

Instructors struggling to generate substantive feedback to their student's work might use the standards to contextualize their comments, as follows:

- [ ] Identify Problem **COMMENT**
- [ ] Acquire Data **COMMENT**
- [ ] Present Data **COMMENT**

---

<a id='feedback'></a>
## V. How to Deliver Feedback

Instructors should devote specific time to check in with students before and after project submission. 

### Before Project Submission

Many instructors have found the use of a *daily stand* method useful for holding students publicly accountable to incremental progress on projects during the week leading up to a deadline. This is a good chance to briefly discuss student progress, next steps, and blockers.

Instructors may alternatively choose to conduct these check-ins individually during office hours.

### After Project Submission

Project feedback can be delivered in many ways. For example, instructors can use Github pull requests, Slack, or email to deliver written comments to their students. We recommend that instructors follow up written feedback with "office hours," 15-30 min blocks of time where students can optionally debrief project evaluations in-person. These are suggested for unit projects, and **required** for capstone projects.

Students should use this time to review their project evaluation or walk through a guided code review (e.g. ask them to explain and debug sections of their code, in order to confirm that they understand how it works).


### Project Feedback Template

In-person project feedback is not troubleshooting time. Instead, the goal is to review the student's code and talk about actionable feedback for enhancing the student's project in the future. Below is a sample framework instructors can use to organize in-person discussions:

- **Student (10 mins)**: Prompt the student walk through and/or defend their project / model / code.

- **Student (10 mins)**: Ask the student answer some sample questions:
  - What do you like most about your project?
  - What would you change if you started from scratch?
  - What would you like to add when you have more time?
  - What goals would you set for yourself for your next project or a future version?

- **Instructonal Team Member (10 mins)**: Talk through the evaluation, share a “glow and grow”.
  - Make it personal – what about the project was exciting or intriguing?
  - Share any highlights and positive areas (“glow”) where the student went “above and beyond” the requirements
  - Share growth areas around time management, workflow, or project approach
  - Share growth areas around technical skills and ways to remediate any difficulties the student encountered
  - Help the student prioritize and identify which growth area is most important to focus on before the next project. 
  - Review their performance against the requirements and explain any rubric scores, if necessary.
  - Ask them to compare their progress against any goals they set previously, if applicable.

- **Instructional Team Member (Followup)**: Be sure to report a summary of your evaluations using your local course tracker. This will help your team identify trends in student performance over time.

---

<a id='example'></a>
## VI. Example Feedback

Below are two examples of feedback on a project asking students to do EDA on Billboard Top 100 data. Both follow a "glow/grow" template, with scores based on the project requirements. This feedback can be delivered via Github PR or email (e.g. copy-pasting from a googledocs), and followed up with an in-person 1:1 review as needed.

### Example 1:

- *Excellent work here. You obviously put a lot of care into this project, and it shows that you're on the track to success. You have good articulations of assumptions and hypothesis, and well-written functions to clean the data. (Do be wary of using special names for variables, though, e.g. 'min'.)*

- *Nice job with the t-test: failing to reject the null was the right choice. One correction: it looks like you need to remove the rap observations from bb.daysToPeak, so that you're comparing the mean of daysToPeak(rap) vs daysToPeak(not-rap). (Maybe the p-value will be < .05 after this.) Also, your visualizations are lacking labels - get in the habit of including these and you'll have an easier time sharing your work with unfamiliar audiences*

Requirement | Score
----- | ------------
**Understand and explain the dataset** | 2
**Plot, visualize and interpret your results** | 1
**Formulate and test hypotheses** | 1
**Total scores (out of 6 possible)** | 4


### Example 2:

- *Great work on this. Definitely went down a good path. Your visualizations are excellent, and are sequenced in a clear, logical way; I love the labeling on the stacked barchart of songs in Top 100 / Top 1. However, it looks like you missed identifying some of the risks in the dataset (small sample, limited time period). On the other hand, your comments made it easy to follow your code.*

- *You should build on this work by more explicitly suggesting some next steps. E.g. it would be interesting if you argued for/against combining the Rock and Rock 'n Roll categories, based on a qualitative assessment in addition to your quantitative assessment of their performance patterns.*

Requirement | Score
----- | ------------
**Understand and explain the dataset** | 1
**Plot, visualize and interpret your results** | 2
**Formulate and test hypotheses** | 2
**Total scores (out of 6 possible)** | 5



### More Tips for Providing Project Feedback

- Provide precise praise
- Identify at least one action step for improvement
- Give context as to why that action step is important
- End with a targeted question related to the action step, that tests whether the student has understood your feedback.

  - **Good Example**: "Great work! Your code is well organized. Good use of breaking tasks into separate functions. I see that in your app.js file you used the variable name x on line 84. Consider using more descriptive variable names. As a code reviewer, this would jump out at me. I want to know what every variable contains just by looking at the variable name itself. I do see some other descriptive variables! If we were to refactor this code, what would you want to rename x on line 84?"

  - **Poor Example**: "Great Work! You’re doing a good job with all this. Do you have any questions about anything?"

---
